model:
  model_name_or_path: meta-llama/Meta-Llama-3.1-8B-Instruct
  lora:
     use: false

data:
  task: gsm8k
  data_dir: outputs/trajs/gsm8k/mcts/Llama-3.1-8B-Instruct/CoT_evals_full_traj_with_reference/n_8_temperature_0.4_n_8/
  debug: false
  max_length: 1400
  format: 'cot'
  max_cots_per_solution: 1
  balance_data: false
  direct_prm: true # Step 1: Correct? Yes. No cot

train:
  output_dir: outputs/trained_models/prm/gsm8k/self-taught/llama3.1-8b-instruct/
  num_train_epochs: 2
  per_device_train_batch_size: 24
  per_device_eval_batch_size: 32
  gradient_accumulation_steps: 4
  gradient_checkpointing: false
  evaluation_strategy: steps
  eval_steps: 200
  learning_rate: 0.00004
  save_steps: 200
  save_total_limit: 3
  logging_steps: 50
  seed: 42
  fp16: false
  bf16: true
  warmup_ratio: 0.1
  report_to: wandb
  eval_on_start: false
  ddp_find_unused_parameters: false